{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06edbd4b",
   "metadata": {},
   "source": [
    "# Comparing your transcripts\n",
    "\n",
    "**NOTE:** Click [here](https://colab.research.google.com/github/senthilchandrasegaran/IDEM105-EDI/blob/main/insights-analysis.ipynb) to open the file in Colab.\n",
    "\n",
    "In this notebook, you will upload the transcript of the songwriting video that you were asked to watch for homework, and examine how your identification of insight-related terms performs when generalised to the transcript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a910a33",
   "metadata": {},
   "source": [
    "## Load Your Transcript\n",
    "Download the [transcript from BrightSpace](https://brightspace.tudelft.nl/d2l/le/content/767143/viewContent/4644865/View) based on the instructions given. Note the file extension. This is a comma-separated values file, or `.csv` file. A CSV file is a text version of a spreadsheet, with each column separation shown using a comma (\",\") or other special character. In our case, since the transcript text itself can have commas, we use a semicolon (\";\") as the separator.\n",
    "\n",
    "#### NOTE:\n",
    "Most modern file navigators keep the file extension hidden. This is not ideal for our work, and can create a number of errors in later exercises. So, to prevent this issue, please do the following:\n",
    "\n",
    "**Mac:** Open \"Finder\" on your Mac, choose Finder > Settings, then click Advanced. Select “Show all filename extensions.”\n",
    "\n",
    "**Windows:** Open \"File Explorer\" your PC, choose \"View\". Go to the \"Show/hide\" section, and make sure \"File name extensions\" is checked on. \n",
    "\n",
    "Since this is a CSV file, you will need to use a python library called *pandas* to read and process files as tables or \"DataFrames\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412aa11-3a72-462b-964f-58e2292e08ea",
   "metadata": {},
   "source": [
    "### Upload the transcript file here.\n",
    "Use the \"upload\" button below to upload your transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c2720-fc01-45ec-87bc-08e00bb84331",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import some necessary libraries that we will use for this analysis.\n",
    "## Libraries are tools to make programs easier to write. \n",
    "## They provide pre-written, reusable chunks of code for particular tasks.\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "## Uncomment the code below and comment the code above if running in Jupyter Notebook/Lab\n",
    "# uploader = widgets.FileUpload(\n",
    "#     accept='.csv',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#     multiple=False  # True to accept multiple files upload else False\n",
    "# )\n",
    "# display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d5842-9af0-4f4c-8375-6be5802b72cc",
   "metadata": {},
   "source": [
    "It is convention to add a `_df` suffix to all variables that represent dataframes. \n",
    "So we save the transcript contents into a variable called `transcript_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "# Use 'pd' as a shortcut for 'pandas' as it saves you the effort of typing 'pandas' every time.\n",
    "\n",
    "transcript_df = pd.read_csv('/content/Morning_Writes_with_Christiana.csv', sep=';')\n",
    "\n",
    "## Uncomment the code below and comment the code above if running in Jupyter Notebook/Lab\n",
    "# uploaded_file = uploader.value[0]\n",
    "# transcript_df = pd.read_csv(io.BytesIO(uploaded_file.content), sep=';')\n",
    "\n",
    "transcript_df.astype({'Utterance': 'str'}).dtypes\n",
    "# Print a random sample of the dataframe, showing 5 rows.\n",
    "transcript_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0f150-6dc3-4676-a260-559971bc9cba",
   "metadata": {},
   "source": [
    "Note the columns show in the above 'sampling' of the table. This is what it would look like as an Excel (or Numbers) file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b5261-c8bf-4e38-9d05-0ae20fb585eb",
   "metadata": {},
   "source": [
    "## Define a list of insight-related words\n",
    "Go back to your notes from your preliminary analysis of transcripts. What words or phrases did you associate with insights?\n",
    "\n",
    "Write the terms down in the text box below, with each term separated by a comma from the previous term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8903d-b74b-4996-8dc6-b2ea341de572",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  widgets.Textarea(\n",
    "    layout={'height': '100%'},\n",
    "    value='wow, yeah, see',\n",
    "    width=100,\n",
    "    placeholder='term1, term2, term3',\n",
    "    description='Enter terms:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54856d-e58a-495b-863a-dff1a5bc7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_terms = [x.lower().strip() for x in text.value.split(',')]\n",
    "print(len(insight_terms), \"insight terms entered. Listing...\")\n",
    "print(insight_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378edab-91cc-48c9-b6b4-09699a35b009",
   "metadata": {},
   "source": [
    "## Finding matches between dictionary and text\n",
    "The next step is to find how many terms from the text match the terms in the dictionary category, and to count every match. Note that I use the word \"term\" and not \"word\", since there are a number of multi-word terms in the dictionary, such as `\"I see\"`. \n",
    "\n",
    "Since we will be using this counting part of the code a lot, it might be good to write it up as a function that we can use multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1d9d4-807c-42fc-b567-be64bad09b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_matches(text, pattern):\n",
    "    if pattern.startswith('*') :\n",
    "        pattern = r\"[A-Za-z]*\" + pattern[1:]\n",
    "        \n",
    "    if pattern.endswith('*') :\n",
    "        pattern = pattern[:-1] + r\"[A-Za-z]*'\"\n",
    "    \n",
    "    m = r\"\\b\" + pattern + r\"\\b\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d92238-9133-43df-9d19-95a96d8dd0b2",
   "metadata": {},
   "source": [
    "## Count terms for the entire transcript\n",
    "Let's start by looking at the entire transcript as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331755b-0f04-4de1-8248-1a24b86bf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')  # comment this line after the first time you run this code.\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Make a single string combining all the utterances\n",
    "transcript_utterances = ' '.join(transcript_df['Utterance'].to_list())\n",
    "\n",
    "def get_insight_counts(utterance_string, list_of_terms):\n",
    "    # Count the total number of times any word from the dictionary appears in the transcript\n",
    "    term_counts = 0\n",
    "    for term in list_of_terms :\n",
    "        term_counts += count_matches(utterance_string.lower(), term)\n",
    "    \n",
    "    tokens = word_tokenize(utterance_string)\n",
    "    word_count = len(tokens)\n",
    "    \n",
    "    normalized_count = term_counts/word_count\n",
    "    return term_counts, word_count, normalized_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e78229-d6bd-49be-b002-9be2308d9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_counts, word_count,insight_counts_normalized = get_insight_counts(transcript_utterances, insight_terms)\n",
    "# print results\n",
    "print('Counting insight terms for your transcript...')\n",
    "print('------------------------------------------------')\n",
    "print(\"Total number of insight terms in transcript:\", insight_counts)\n",
    "print(\"Total number of words in transcript:\", word_count)\n",
    "print(f'Fraction of insight terms for the transcript: {insight_counts_normalized: .4f}')\n",
    "print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5305-9da6-469e-93f3-68bfc1491c5b",
   "metadata": {},
   "source": [
    "## Concordance Analysis/ KeyWord in Context (KWIC) visualization\n",
    "\n",
    "To verify if your insight terms indeed appear in the context of insights, it might be a good idea to examine the contexts of word use.\n",
    "\n",
    "For this purpose, we use a KWIC or KeyWord In Context view that shows all occurrences of a word of interest in the context of its surrounding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862a16c-10bd-4cbc-b396-994b33708013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "\n",
    "# enter the variable corresponding to the text you plan to examine\n",
    "text_to_examine = transcript_utterances\n",
    "\n",
    "tokens = word_tokenize(text_to_examine.lower())\n",
    "textList = Text(tokens)\n",
    "\n",
    "term_for_kwic = insight_terms[2]\n",
    "\n",
    "if term_for_kwic in text_to_examine.lower() :\n",
    "    print(\"looking for occurrences of\", term_for_kwic, \"...\")\n",
    "    textList.concordance(term_for_kwic, width=125, lines=25)\n",
    "else :\n",
    "    print(term_for_kwic, \"is not found in text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dbe784-ee9b-4c58-8f24-f982dc15ed6a",
   "metadata": {},
   "source": [
    "## Analyse transcript by speech turns\n",
    "\n",
    "We analysed the transcript as a single unit of text, but can we analyse it over time to see when insights occur, and by whom?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d811d0-1a2a-44a7-8bff-b4e64c34c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df[[\"Insight Count\", \"Word Count\", \"Norm Insight Count\"]]  = transcript_df.apply(lambda row: get_insight_counts(row[\"Utterance\"], insight_terms), axis='columns', result_type='expand') \n",
    "transcript_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1301ec5-d508-4d43-af46-49f804ed52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(timestamp_str):\n",
    "    hms = [int(x) for x in timestamp_str.split(\":\")]\n",
    "    seconds = hms[0] * 3600 + hms[1] * 60 + hms[2]\n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17dab4d-9e19-43a1-a077-12ae5c5ce6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df[\"Timestamp (sec)\"] = transcript_df[\"Timestamp\"].apply(convert_to_seconds)\n",
    "transcript_df.to_excel(\"transcript_with_measures.xlsx\")\n",
    "transcript_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa23093-2440-4dd4-ac07-8e2ac1eec926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure(figsize=[20,4], dpi=600)\n",
    "nonzero_df = transcript_df[transcript_df[\"Norm Insight Count\"] > 0]\n",
    "g = sns.scatterplot(data=nonzero_df, x=\"Timestamp (sec)\", y=\"Norm Insight Count\", alpha=0.5)\n",
    "\n",
    "# Custom format x-ticks every 600 seconds (10 mins)\n",
    "space = 600\n",
    "g.xaxis.set_major_locator(ticker.MultipleLocator(space))\n",
    "\n",
    "# Convert labels from seconds to minutes for easier readability\n",
    "xticklabels = g.get_xticks()\n",
    "label_str_list = [''] + [str(int(label/60)) for label in xticklabels[1:-1]] + ['']\n",
    "g.xaxis.set_ticks(xticklabels)\n",
    "g.set_xticklabels(label_str_list)\n",
    "g.set_xlabel(\"Timestamp (min)\")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"insight_plot.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607dadc-b79c-43ee-95d3-054d8d44b14b",
   "metadata": {},
   "source": [
    "### Plotting insights separately for each speaker\n",
    "We exclude Michael and Preston from the speakers and focus only on the songwriters, Christiana and Emily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646aebd-0c9b-45e2-a148-b9ac605a80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[20,12], dpi=600)\n",
    "# Focus on Emily & Christiana\n",
    "singers_df = nonzero_df[(nonzero_df['Speaker'] == 'Christiana') | (nonzero_df['Speaker'] == 'Emily') ]\n",
    "g = sns.FacetGrid(singers_df, row=\"Speaker\", height=2, aspect=10, hue=\"Speaker\", palette=sns.color_palette(\"Set2\"))\n",
    "g.map(sns.scatterplot, \"Timestamp (sec)\", \"Norm Insight Count\", alpha=0.8)\n",
    "\n",
    "# Convert labels from seconds to minutes for easier readability\n",
    "# Custom format x-ticks every 600 seconds (10 mins)\n",
    "space = 600\n",
    "g.axes[1][0].xaxis.set_major_locator(ticker.MultipleLocator(space))\n",
    "xticklabels = g.axes[1][0].xaxis.get_ticklabels()\n",
    "label_str_list = [str(int(float(label.get_text())/60)) for label in xticklabels[1:-1]]\n",
    "g.axes[1][0].xaxis.set_ticks([int(float(x.get_text())) for x in xticklabels[1:-1]])\n",
    "g.axes[1][0].set_xticklabels(label_str_list)\n",
    "g.axes[1][0].set_xlabel(\"Timestamp (min)\")\n",
    "\n",
    "plt.savefig(\"insight_plot_speakers.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0f927-ae03-4da3-89a5-5f5b502e3fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
