{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610eac7b-eba9-4286-bb13-1085ab8a34f9",
   "metadata": {},
   "source": [
    "# Analyse your transcript\n",
    "What kind of behaviour would you like to analyse in your transcript? Use ChatGPT or any equivalent LLM-based application to give you a list of terms that relate to this particular behaviour. Use the prompt below if you like, or use your own.\n",
    "\n",
    "---\n",
    "#### NOTE:  \n",
    "Replace **'______'** in the prompt below with a term that best describes the kind of behaviour you'd like to examine.\n",
    "\n",
    "### Prompt to use:\n",
    "\n",
    "Generate a list of words that could be used in a LIWC-like dictionary to identify instances of ______ in a transcript of a conversation between two or more people. Do not use wildcard characters, provide all inflected forms of words that might otherwise appear in a LIWC dictionary as wildcards. Make sure the list is all in lowercase, ordered alphabetically, with each set of inflected forms of a word together on the same line. Output this in the form of a list of strings that can be copied and pasted into python code as a list.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc805036-74f0-4a2d-9907-673885b0ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from functools import reduce \n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3586623-1c28-4a65-bae7-618b43a5b71d",
   "metadata": {},
   "source": [
    "## Define your measure terms and give the measure a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf29e07-5b1b-4509-af35-6196d1b10e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the output from the LLM and paste it next to the variable named \"measure_words\" below \n",
    "# Make sure you have also copied the square braces [ ] that were part of the LLM output.\n",
    "\n",
    "measure_words = [ ]\n",
    "\n",
    "# Give your measure a single- or two-word name. \n",
    "# Replace the 'XXXX' below with the name.\n",
    "# Make sure the name is enclosed in single or double quotation marks\n",
    "measure_name = 'XXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1906fb-d545-4197-99f0-01848a0f6cf7",
   "metadata": {},
   "source": [
    "# Load Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fcecd-23b5-448d-aa30-76b60071137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **** USE THE CODE BELOW IF USING GOOGLE COLAB. COMMENT OUT THE REST. ****\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "## **** USE THE CODE BELOW IF USING JUPYTER NOTEBOOK/LAB. COMMENT OUT THE REST. ****\n",
    "# import io\n",
    "# import ipywidgets as widgets\n",
    "# uploader = widgets.FileUpload(\n",
    "#     accept='.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#     multiple=False  # True to accept multiple files upload else False\n",
    "# )\n",
    "# display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fdf90-c2df-4dee-bb30-e06d8185da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **** USE THE CODE BELOW IF USING GOOGLE COLAB. COMMENT OUT THE REST. ****\n",
    "# Copy the file path from the navigator to the left. Paste it into the '' sign within the function below.\n",
    "transcript_df = pd.read_excel('')\n",
    "\n",
    "## **** USE THE CODE BELOW IF USING JUPYTER NOTEBOOK/LAB. COMMENT OUT THE REST. ****\n",
    "# uploaded_file = uploader.value[0]\n",
    "# transcript_df = pd.read_excel(io.BytesIO(uploaded_file.content))\n",
    "\n",
    "## **** KEEP THIS BIT OF THE CODE REGARDLESS OF COLAB/JUPYTER USAGE ****\n",
    "print('###############################################')\n",
    "print(\"Loaded\", transcript_df.shape[0], \"speech turns into a dataframe.\")\n",
    "print('###############################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819aa4b-051e-45ab-8d16-e104c883ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random sample of the dataframe, showing 5 rows.\n",
    "transcript_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b37ea3-f889-47db-9f7b-beb8792429ea",
   "metadata": {},
   "source": [
    "## Counting Relevant Terms in the Dataset\n",
    "We now count the number of terms in each utterance that also exist in the above list of measure-related terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf235e9-fdf6-4ecc-9954-2583f8b8c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regex(lex_list):\n",
    "    separator = '\\\\b|\\\\b'\n",
    "    reg_string = separator.join(lex_list)\n",
    "    reg_string_whole_word = \"\\\\b\" + reg_string + \"\\\\b\"\n",
    "    return reg_string_whole_word\n",
    "\n",
    "def count_lexicon_terms(sentence, lexicon):\n",
    "    reg_str = make_regex(lexicon)\n",
    "    num_matches = len(list(re.finditer(reg_str, sentence.lower())))\n",
    "    return num_matches\n",
    "\n",
    "def count_words(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762078d-63c9-4627-a84f-0afb96a7689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_measure(df, lex_category_name, lex_category_list):\n",
    "    if lex_category_name in df.columns :\n",
    "        print(\"Column already exists for\", lex_category_name, \". Repopulating...\")\n",
    "        df = df.drop(lex_category_name, axis=1)\n",
    "    column_index = len(df.columns)\n",
    "    measures = []\n",
    "    measures_normalized = []\n",
    "    word_counts = []\n",
    "    for ind, utterance in enumerate(list(df['utterance'])) :\n",
    "        if utterance != '' and utterance != ' ' :\n",
    "            measure = count_lexicon_terms(utterance, lex_category_list)\n",
    "            num_words = count_words(utterance)\n",
    "            word_counts.append(num_words)\n",
    "            measures_normalized.append(measure/num_words)\n",
    "            measures.append(measure)\n",
    "    df.insert(column_index, 'normalized '+lex_category_name+' measure', measures_normalized, True)\n",
    "    df.insert(column_index, lex_category_name+' count', measures, True)\n",
    "    if not 'word count' in df.columns :\n",
    "        df.insert(column_index, 'word count', word_counts, True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189a252-e2f7-4fbd-a1a0-5448d30cdbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df = add_measure(transcript_df, measure_name, measure_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836207e0-0255-41a6-9aa3-9d448a0c7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd1086-7f95-45e4-ab8a-405fb76ef63e",
   "metadata": {},
   "source": [
    "## Overview of speaker participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53273eab-6035-4a19-a17c-18e14d9b97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = list(set(transcript_df['speaker'].to_list()))\n",
    "num_speakers = len(speakers)\n",
    "word_count_df = transcript_df[['speaker', 'word count']].copy()\n",
    "word_count_df['total word count'] = word_count_df.groupby('speaker')['word count'].transform('sum')\n",
    "word_count_df = word_count_df[['speaker', 'total word count']].drop_duplicates()\n",
    "\n",
    "measure_count_df = transcript_df[['speaker', measure_name+' count']].copy()\n",
    "measure_count_df['total '+measure_name+' count'] = measure_count_df.groupby('speaker')[measure_name+' count'].transform('sum')\n",
    "measure_count_df = measure_count_df[['speaker', 'total '+measure_name+' count']].drop_duplicates()\n",
    "\n",
    "\n",
    "turn_counts = []\n",
    "for speaker in speakers :\n",
    "    turn_count = transcript_df[transcript_df['speaker'] == speaker].shape[0]\n",
    "    turn_counts.append(turn_count)\n",
    "turns_df = pd.DataFrame({'speaker': speakers, 'turn count': turn_counts})\n",
    "# speaker_stats_df = pd.merge(word_count_df, turns_df, on=\"speaker\")\n",
    "speaker_stats_df = reduce(lambda  left,right: pd.merge(left,right,on='speaker'), [word_count_df, measure_count_df, turns_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5035b-c83b-478e-af35-518f0ed34960",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_stats_df['normalised '+measure_name+' count'] = speaker_stats_df['total '+measure_name+' count']/speaker_stats_df['total word count']\n",
    "speaker_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de409c8a-5e26-4b1c-8820-244cb3189122",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale = 1)\n",
    "f, ax = plt.subplots(figsize=(7, num_speakers*0.5))\n",
    "sns.barplot(data=speaker_stats_df, x='turn count', y='speaker', hue='speaker', palette ='Set2', linewidth=0)\n",
    "ax.set(ylabel=\"\", xlabel=\"Total \"+ r\"$\\bf{speech~turns}$\" + \" by each speaker\")\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cf8d6-1ffb-454e-ad5b-48457f919092",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale = 1)\n",
    "f, ax = plt.subplots(figsize=(7, num_speakers*0.5))\n",
    "sns.barplot(data=speaker_stats_df, x='total word count', y='speaker', hue='speaker', palette ='Set2', linewidth=0)\n",
    "ax.set(ylabel=\"\", xlabel=\"Total \"+ r\"$\\bf{words~spoken}$\" + \" by each speaker\")\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6ad2f-ae26-40c3-823b-f2f7282d0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale = 1)\n",
    "f, ax = plt.subplots(figsize=(7, num_speakers*0.5))\n",
    "sns.barplot(data=speaker_stats_df, x='total word count', y='speaker', color ='#eee', linewidth=0)\n",
    "sns.barplot(data=speaker_stats_df, x='total '+ measure_name + ' count', y='speaker', hue='speaker', palette ='Set2', linewidth=0)\n",
    "ax.set(ylabel=\"\", xlabel= r\"$\\bf{\" + \"~\".join(measure_name.split(\" \")) + \"}$-related words in proportion to total words spoken by each speaker\")\n",
    "sns.despine(right=True, top=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a654be-439e-4dc1-93f2-81e911e4ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale = 1)\n",
    "f, ax = plt.subplots(figsize=(7, num_speakers*0.5))\n",
    "sns.barplot(data=speaker_stats_df, x='normalised '+ measure_name + ' count', y='speaker', hue='speaker', palette ='Set2', linewidth=0)\n",
    "ax.set(ylabel=\"\", xlabel=r\"$\\bf{\" + \"~\".join(measure_name.split(\" \")) + \"}$-related words by each speaker (normalised)\")\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad23ac-a46f-461d-ab23-bb866182e008",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Note the differences between the number of words and the proportion (the two charts above). Is there a large difference in your case? \n",
    "\n",
    "Normalisation can distort reality, so it is important to examine the data from multiple perspectives.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d8a6b-40da-479e-883c-afe199be7379",
   "metadata": {},
   "source": [
    "## Compute overall scores for the chosen measure\n",
    "To compute the overall score for the measure, simply count all the occurrances of words from the dictionary category in the transcript, and divide that value by the total words in the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6901c-0166-44ed-bc59-f8b3434386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "total_word_count = speaker_stats_df['total word count'].sum()\n",
    "total_measure_words = speaker_stats_df['total '+measure_name+' count'].sum()\n",
    "normalised_measure_for_transcript = total_measure_words/total_word_count\n",
    "printmd(\"------\")\n",
    "print(\"\")\n",
    "printmd(\"**%d** words from the **\" % (total_measure_words) + measure_name + \"** category found in the transcript out of **%d** total words.\" % (total_word_count))\n",
    "printmd(\"Normalised **\" + measure_name + \"** score for the entire transcript: **%1.3f**\" % (normalised_measure_for_transcript))\n",
    "printmd(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08cb005-bbda-40df-8100-e30d908d548a",
   "metadata": {},
   "source": [
    "## Examine word usage in detail\n",
    "\n",
    "How do we know whether what you have identified (using dictionary categories and word counts) is accurate?\n",
    "\n",
    "We can plot the occurrences at the speaker level to begin with.\n",
    "\n",
    "### Plot turn-level word counts for each speaker\n",
    "\n",
    "Let's start with visualising the number of words spoken for each turn. We do this separately for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959220d-cc3c-4ce5-8f72-c3b48839fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_turns = transcript_df.shape[0]\n",
    "transcript_df['turn index'] = np.arange(0,session_turns)\n",
    "sns.set_style('ticks', {'axes.linewidth': 0.5, 'axes.edgecolor':'grey', 'axes.spinecolor' : 'grey'})\n",
    "sns.set_context('talk', font_scale = 1)\n",
    "# fig = plt.figure(dpi=200)\n",
    "g = sns.FacetGrid(transcript_df, row=\"speaker\", aspect=10)\n",
    "g.map_dataframe(sns.barplot, x =transcript_df[\"turn index\"], y=\"word count\", color=\"cornflowerblue\", linewidth=0)\n",
    "p = plt.xticks(np.arange(0, session_turns, 20))\n",
    "plt.xlabel('Speech Turn Index')\n",
    "# plt.title(\"Word count for each speaker over the duration of the conversation\", fontsize=14)\n",
    "plt.savefig('./plots/speech_turns.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0d16c-2fe0-495f-aa61-6aeb8b8bc221",
   "metadata": {},
   "source": [
    "### Plot turn-level occurrances of words from chosen dictionary category\n",
    "\n",
    "We can then examine the occurrences of the words from the chosen dictionary category in proportion to the total words per speech turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367efca-4d2b-4974-9d2b-4f2311213e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measure(df1, measure, show_all=False):\n",
    "    session_turns = df1.shape[0]\n",
    "    df1['zero_index'] = np.arange(0,session_turns)\n",
    "    col = sns.color_palette(\"Set2\")\n",
    "    sns.set_style('ticks', {'axes.linewidth': 0.5, 'axes.edgecolor':'grey', 'axes.spinecolor' : 'grey'})\n",
    "    sns.set_context('talk', font_scale = 1)\n",
    "    fig = plt.figure(figsize=[round(session_turns/20),4], dpi=300)\n",
    "    if show_all :\n",
    "        sns.barplot(x=df1.zero_index, y='word count', data=df1, color ='#eee', linewidth=0)\n",
    "        ax = sns.barplot(x=df1.zero_index, y=measure+' count', data=df1, hue='speaker', palette ='Set2', linewidth=0)\n",
    "        plt.title(\"Speech turn-wise word count with non-normalised measure for: \" + measure, fontsize=9)\n",
    "        ax.set_ylabel(\"word / \" + measure + \" counts\\n(non-normalised)\")\n",
    "    else :\n",
    "        ax = sns.barplot(x=df1.zero_index, y='normalized '+measure+' measure', data=df1, hue='speaker', palette ='Set2', linewidth=0)\n",
    "        plt.title(\"Speech turn-wise normalised measure for: \" + measure, fontsize=13)\n",
    "        ax.set_ylabel(measure+\" score\\n(normalised)\")\n",
    "        \n",
    "    plt.xticks(np.arange(0, session_turns, 20))\n",
    "    ax.set_xlabel(\"Turn Index\")\n",
    "    speakers = len(set(list(df1['speaker'])))\n",
    "    legend_columns = round(speakers/4) + 1\n",
    "    plt.legend(loc='best', ncol=legend_columns, borderaxespad=0.15)\n",
    "    plt.savefig('./plots/'+ measure +'.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189719b-5380-423d-8701-ac979f8427a3",
   "metadata": {},
   "source": [
    "#### HINT:\n",
    "If you want only the normalised measure, set `show_all = False` in the function call below. \n",
    "\n",
    "However, if you want to see the number of words from the dictionary category plotted against the total words spoken for each turn, set `show_all = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd194f7d-deb2-4cd1-85ee-a29cc188b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measure(transcript_df, measure_name, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6a5e4-3bf2-4b7c-8e09-7d32104b816d",
   "metadata": {},
   "source": [
    "### Examine the word occurrances in context\n",
    "\n",
    "Choose a particular interval from the figure above based on what activity around your chosen behaviour you would like to examine.\n",
    "\n",
    "Select a turn index closest to the activity and examine the text that follows this turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2bbfb-8d04-47f1-b7cd-42550209d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lexicon_terms(sentence, lexicon):\n",
    "    reg_str = make_regex(lexicon)\n",
    "    reg_matches = re.findall(reg_str, sentence.lower())\n",
    "    reg_split = re.split(reg_str, sentence.lower())\n",
    "    ind = 0\n",
    "    matched_print = \"\"\n",
    "    for split_string in reg_split:\n",
    "        if ind == len(reg_matches) :\n",
    "            str_to_concat = split_string\n",
    "        else :\n",
    "            str_to_concat = split_string + '**' + reg_matches[ind] + '**'\n",
    "            ind += 1\n",
    "        matched_print += str_to_concat\n",
    "    return matched_print\n",
    "    \n",
    "def print_lines(df2, lexicon, start, num_lines=10):\n",
    "    speakers_list = list(df2['speaker'])\n",
    "    utt = list(df2['utterance'])\n",
    "    end = start + num_lines\n",
    "    for ind, line in enumerate(utt[start:end]) :\n",
    "        index = ind + start\n",
    "        line_matched = match_lexicon_terms(line, lexicon)\n",
    "        print(str(index)+' : ', end='')\n",
    "        print(speakers_list[index])\n",
    "        printmd(line_matched)\n",
    "        print('----------')\n",
    "        \n",
    "def concordance(text, word, width=80, occurrences=10,nospace=False):\n",
    "    margin = int((width - len(word))/2)\n",
    "    start = 0\n",
    "    counter = 0\n",
    "    while start < len(text) or counter == occurrences:\n",
    "        ind = text.find(word, start, -1)\n",
    "        if ind < 0 :\n",
    "            break\n",
    "        \n",
    "        if nospace : \n",
    "            \n",
    "            if ind - margin > 0 :\n",
    "                print(text[ind-margin:ind+len(word)+margin], \":\", str(ind))\n",
    "            else :\n",
    "                spaces = ' ' * (margin - ind)\n",
    "                print(spaces + text[0:ind+len(word)+margin], \":\", str(ind))\n",
    "            \n",
    "        else :\n",
    "            \n",
    "            if ind - margin > 0 :\n",
    "                left_text = text[ind-margin:ind]\n",
    "                mid_text = text[ind:ind+len(word)]\n",
    "                right_text = text[ind+len(word):ind+len(word)+margin]\n",
    "            else :\n",
    "                left_text = text[0:ind]\n",
    "                mid_text = text[ind:ind+len(word)]\n",
    "                right_text = text[ind+len(word):ind+len(word)+margin]\n",
    "                \n",
    "            print(left_text + \"  \" + mid_text + \"  \" + right_text, \":\", str(ind))\n",
    "            \n",
    "        start += ind + len(word)\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "def print_concordances(df2, filter_keywords, match_limit=10, nospace=False):\n",
    "    speakers_list = list(df2['speaker'])\n",
    "    utt = list(df2['utterance'])\n",
    "    utt_str = ' '.join(utt)\n",
    "    if len(filter_keywords) > 0 :\n",
    "        for term in filter_keywords :\n",
    "            concordance(utt_str, term, width=80, occurrences=match_limit, nospace=nospace)\n",
    "            print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea868da-d908-4f9e-8902-6d629d9259be",
   "metadata": {},
   "source": [
    "#### HINT:\n",
    "If you want to see more speech turns, increase the `num_lines` value in the function call below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3eef4-43a5-43fb-84d3-9a6d476dd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lines(transcript_df, measure_words, 35, num_lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209bf83-22a7-4cf4-bd7e-eca2f1ce34cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a403ad2-cf5c-4e71-849c-7dcc318e6ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
