{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06edbd4b",
   "metadata": {},
   "source": [
    "# Comparing your transcripts\n",
    "\n",
    "**NOTE:** Click [here](https://colab.research.google.com/github/senthilchandrasegaran/IDEM105-EDI/blob/main/04-comparing-transcripts.ipynb) to open the file in Colab.\n",
    "\n",
    "In this notebook, you will compare your own transcript with all the transcripts from the post-it exercise (download the combined transcript from BrightSpace) using the dictionary category of your choice. Make sure you download the appropriate dictionary category from BrightSpace. \n",
    "\n",
    "You will also compare your transcript to a non-design transcript to examine any differences in the score, and use KWIC to see if the context of the utterances align with the description of your dictionary category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a910a33",
   "metadata": {},
   "source": [
    "## Load Your Transcript\n",
    "Let's load your Transcript file from BrightSpace. At this point you would already have the file on your after the exercise from the last class.\n",
    "If you are using Colab, you would need to first upload the file to Google Drive and then specify the link in the `read_excel` command below.\n",
    "\n",
    "Since this is an excel file, you will need to use a python library called *pandas* to read and process files as tables or \"DataFrames\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b42e5e-cb61-4646-a78a-e1e259ae7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "# Use 'pd' as a shortcut for 'pandas' as it saves you the effort of typing 'pandas' every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d5842-9af0-4f4c-8375-6be5802b72cc",
   "metadata": {},
   "source": [
    "It is convention to add a `_df` suffix to all variables that represent dataframes. So we load the transcript into a variable called `transcript_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a9feb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>00:44:19</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>I found the glue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>00:02:48</td>\n",
       "      <td>Bravo</td>\n",
       "      <td>That we can also do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>00:35:46</td>\n",
       "      <td>Bravo</td>\n",
       "      <td>Yes it does.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>00:30:37</td>\n",
       "      <td>Bravo</td>\n",
       "      <td>I can see it sinking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>00:07:05</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>Ah.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  speaker              utterance\n",
       "620  00:44:19  Charlie      I found the glue.\n",
       "47   00:02:48    Bravo   That we can also do.\n",
       "517  00:35:46    Bravo           Yes it does.\n",
       "461  00:30:37    Bravo  I can see it sinking.\n",
       "145  00:07:05    Alpha                    Ah."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df = pd.read_excel('./data/sample_transcript.xlsx')\n",
    "transcript_df.astype({'utterance': 'str'}).dtypes\n",
    "# Print a random sample of the dataframe, showing 5 rows.\n",
    "transcript_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f65eda",
   "metadata": {},
   "source": [
    "# Load the reference dataset of transcripts\n",
    "\n",
    "You can download the reference dataset of transcripts that we have prepared for you (download from BrightSpace). This is an aggregation of all your transcripts, anonymized to a large extent. Load this into a separate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd14c55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>00:19:28</td>\n",
       "      <td>speaker4</td>\n",
       "      <td>It's interesting.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>00:03:42</td>\n",
       "      <td>unclear</td>\n",
       "      <td>(Confusion)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>NaN</td>\n",
       "      <td>speaker1</td>\n",
       "      <td>Making people happy and now we are ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00:02:17</td>\n",
       "      <td>speaker2</td>\n",
       "      <td>I think I like the 3d thing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>speaker4</td>\n",
       "      <td>Yeah, you didn’t ?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp   speaker                               utterance  group\n",
       "2614  00:19:28  speaker4                       It's interesting.      8\n",
       "2430  00:03:42   unclear                             (Confusion)      8\n",
       "1519       NaN  speaker1  Making people happy and now we are ...      5\n",
       "32    00:02:17  speaker2            I think I like the 3d thing.      1\n",
       "1204       NaN  speaker4                      Yeah, you didn’t ?      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_excel('./data/all-transcripts.xlsx')\n",
    "all_df['utterance'] = all_df['utterance'].astype(str)\n",
    "all_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc8bc3",
   "metadata": {},
   "source": [
    "Youn can see that the group ID is mentioned in an extra column. This is in case you want to try some group-level comparison, but for now let's ignore the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fbd11e-c677-46a4-b17c-cc8715accf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms in dictionary: 383\n"
     ]
    }
   ],
   "source": [
    "with open('./data/dictionaries/EDI-insight.txt', 'r') as fo:\n",
    "    dictionary_terms_list = fo.readlines()\n",
    "\n",
    "# We get rid of extraneous carriage return (\\n) characters from the text\n",
    "dictionary_terms_list = [w.strip('\\n') for w in dictionary_terms_list]\n",
    "print(\"Number of terms in dictionary:\", len(dictionary_terms_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378edab-91cc-48c9-b6b4-09699a35b009",
   "metadata": {},
   "source": [
    "## Finding matches between dictionary and text\n",
    "The next step is to find how many terms from the text match the terms in the dictionary category, and to count every match. Note that I use the word \"term\" and not \"word\", since there are a number of multi-word terms in the dictionary, such as `realize that`. \n",
    "\n",
    "There are also some wildcards, indicated by `*`. A wildcard character indicates a general pattern. For instance, `option*` will return a match to `option`, `options`, `optional`, and `optionally`. \n",
    "\n",
    "Due to these wildcards and multi-word terms, we cannot simply use a token-by-token match to perform dictionary term matching. Instead, we will have to find patterns in the original text that match the patterns indicated in the dictionary entries. This includes single- and multi-word terms as well as terms that use wildcards. To achieve this, we will use a concept called [**regular expressions**](https://en.wikipedia.org/wiki/Regular_expression). In python, regular expressions are largely implemented using the [\"`re`\" library](https://docs.python.org/3/howto/regex.html#regex-howto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce1d9d4-807c-42fc-b567-be64bad09b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_matches(text, pattern):\n",
    "    if pattern.startswith('*') :\n",
    "        pattern = r\"[A-Za-z]*\" + pattern[1:]\n",
    "        \n",
    "    if pattern.endswith('*') :\n",
    "        pattern = pattern[:-1] + r\"[A-Za-z]*'\"\n",
    "    \n",
    "    m = r\"\\b\" + pattern + r\"\\b\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d92238-9133-43df-9d19-95a96d8dd0b2",
   "metadata": {},
   "source": [
    "## Compute dictionary category score for the entire transcript\n",
    "In the last workshop we computed the dictionary category score for individual turns. This time since we are comparing transcripts, let's perform an aggregate score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d331755b-0f04-4de1-8248-1a24b86bf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')  # comment this line after the first time you run this code.\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Make a single string combining all the utterances\n",
    "transcript_utterances = ' '.join(transcript_df['utterance'].to_list())\n",
    "\n",
    "def get_category_score(utterance_string, category_term_list):\n",
    "    # Count the total number of times any word from the dictionary appears in the transcript\n",
    "    term_counts = 0\n",
    "    for dict_term in category_term_list :\n",
    "        term_counts += count_matches(utterance_string.lower(), dict_term)\n",
    "    \n",
    "    # Count the total words in the transcript\n",
    "    tokens = word_tokenize(utterance_string)\n",
    "    word_count = len(tokens)\n",
    "    \n",
    "    # Compute dictionary category score\n",
    "    category_score = term_counts/word_count\n",
    "\n",
    "    # print results\n",
    "    print('#####################################')\n",
    "    print(\"Total number of matches for the dictionary category:\", term_counts)\n",
    "    print(\"Total number of words in the transcript:\", word_count)\n",
    "    print(f'Dictionary category score for the transcript: {category_score: .4f}')\n",
    "    print('#####################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e78229-d6bd-49be-b002-9be2308d9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################\n",
      "Computing score for YOUR transcript:\n",
      "#####################################\n",
      "Total number of matches for the dictionary category: 145\n",
      "Total number of words in the transcript: 6444\n",
      "Dictionary category score for the transcript:  0.0225\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "print('#####################################')\n",
    "print('Computing score for YOUR transcript:')\n",
    "get_category_score(transcript_utterances, dictionary_terms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200b326-550b-4d7b-b399-869dd7463c1e",
   "metadata": {},
   "source": [
    "## Perform same analysis on aggregate transcript\n",
    "Let's compare this with the aggregate transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68df154b-6038-4f91-8116-75a752659c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################\n",
      "Computing score for ALL transcripts:\n",
      "#####################################\n",
      "Total number of matches for the dictionary category: 1417\n",
      "Total number of words in the transcript: 50609\n",
      "Dictionary category score for the transcript:  0.0280\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "all_utterances = ' '.join(all_df['utterance'].to_list())\n",
    "\n",
    "print('#####################################')\n",
    "print('Computing score for ALL transcripts:')\n",
    "get_category_score(all_utterances, dictionary_terms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f8047-1182-43b1-a1b8-45ecac849758",
   "metadata": {},
   "source": [
    "# Import a non-design transcript\n",
    "Download from BrightSpace the copy of a non-design transcript (in this case, the dataset consists of transcripts from [post-match tennis interviews](https://www.cs.cornell.edu/~liye/tennis.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3b5b35-e79d-4cd2-afd6-1c9bced1f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/tennis_finals_interview.txt', 'r') as fo:\n",
    "    tennis_utterance_str = fo.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53d37ef-30de-42ed-85cb-a61fa15e739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################\n",
      "Computing score for NON-DESIGN transcript:\n",
      "#####################################\n",
      "Total number of matches for the dictionary category: 34031\n",
      "Total number of words in the transcript: 884140\n",
      "Dictionary category score for the transcript:  0.0385\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "print('#####################################')\n",
    "print('Computing score for NON-DESIGN transcript:')\n",
    "get_category_score(tennis_utterance_str, dictionary_terms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5305-9da6-469e-93f3-68bfc1491c5b",
   "metadata": {},
   "source": [
    "## Concordance Analysis\n",
    "\n",
    "Since dictionary-based scores are not sensitive to the contexts of word use, it might be a good idea to examine the contexts of word use.\n",
    "\n",
    "For this purpose, we use a KWIC or KeyWord In Context view that shows all occurrences of a word of interest in the context of its surrounding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3862a16c-10bd-4cbc-b396-994b33708013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for occurrences of believe ...\n",
      "Displaying 1 of 1 matches:\n",
      "ting . does n't it do time lapse but i believe if you like ask your phone or whatever\n",
      "Looking for occurrences of choose ...\n",
      "Displaying 1 of 1 matches:\n",
      "st make it from the back then , we can choose which way it goes to the camera . fina\n",
      "Looking for occurrences of concentrate ...\n",
      "no matches\n",
      "Looking for occurrences of decide ...\n",
      "Displaying 1 of 1 matches:\n",
      "ee people . yeah . yeah… we can always decide to make it flat [ [ slams table ] ] [ \n",
      "Looking for occurrences of explain ...\n",
      "Displaying 3 of 3 matches:\n",
      "? [ '00:11:03 ' , 'alpha ' ] should we explain what we 're doing ? is that in the des\n",
      "ap this couple as well . always when i explain to people like oh , i do ide , yes , v\n",
      " . yeah no and then i end up having to explain that i fold a duck today . folded a du\n",
      "Looking for occurrences of feel ...\n",
      "Displaying 1 of 1 matches:\n",
      "regular video around . yeah exactly . i feel like halfway through it was the best . \n",
      "Looking for occurrences of feels ...\n",
      "Displaying 2 of 2 matches:\n",
      "on . here . ok. this is all tape . this feels so wasteful . do you think that if we b\n",
      "tiful is this duck . yeah , lovely . it feels so alive . so intelligent . it 's a ver\n",
      "Looking for occurrences of find ...\n",
      "Displaying 3 of 3 matches:\n",
      "aughter ] so it seems like the post-its find their way onto the wall by themselves .\n",
      "know how a duck works . maybe we should find the reference . [ laughter ] maybe we s\n",
      " . well we ’ re 20 minutes in , let ’ s find a picture of a duck . [ laughter ] we h\n",
      "Looking for occurrences of found ...\n",
      "Displaying 3 of 3 matches:\n",
      "itely do that . just left the thing . i found an extra solution . this also works . t\n",
      " something . oh here it sticks yeah . i found the glue . found the glue . very nice .\n",
      "ere it sticks yeah . i found the glue . found the glue . very nice . right then we ju\n",
      "Looking for occurrences of how ...\n",
      "Displaying 25 of 26 matches:\n",
      "should make a , a , a video , like eh .. how do you call it . you put images together\n",
      "ake it smaller after right ? like this , how do how do you want to do it 3d . i was t\n",
      "smaller after right ? like this , how do how do you want to do it 3d . i was thinking\n",
      "going to compress more and more based on how long it ’ s gon na take ? yeah , i do it\n",
      " fill kind of peace for the other side . how big is it gon na be ? it 's kinda small \n",
      "hese are pretty sturdy . yeah . you know how to make them . it 's just two papers and\n",
      " . you make square or like i do n't know how many square . triangles . that 's also f\n",
      "ter when we have the ... have the body . how high are we gon na go ? i think one more\n",
      "roblem that comes back . still working . how was your day ? very ducky , alright . th\n",
      "ke something i guess that is not doing . how do we connect this layer and the top lay\n",
      "t this layer and the top layer ? sorry ? how do we connect this layer and the top lay\n",
      "is ? yeah . or like this . i do n't know how a duck works . maybe we should find the \n",
      "eautiful duck . it 's quite sturdy . ok. how are we gon na do the head . umm . one pr\n",
      " like an anchorage . all right . look at how beautiful is this duck . yeah , lovely .\n",
      " . and it looks kind of fun too . yeah . how many are we going ? a few on both sides \n",
      "is it like this ? okay in your post-it . how did you do that one ? i did it by fold i\n",
      " i will make this front a little cuter . how many post-its do we have left ? cause i \n",
      "ah . i think from here just going down . how big are you making the head ? how big do\n",
      "down . how big are you making the head ? how big do i need to make the snout ? maybe \n",
      "n i try ? yeah . yeah , actually . now , how do we attach it ? i am not at that stage\n",
      "ere and we can fix it after . problems . how ? it can be lower at all right , if it n\n",
      " 's all right . i 'll stop touching it . how 's our time laps coming along ? on this \n",
      "video . around it , yeah . it 's loading how long is it ? i do n't know . it is very \n",
      "owly . yes . let 's do that . let 's see how long it stays there . it gets to like be\n",
      "this . that 's all right . i 'm thinking how i 'm going to do this . i think . i 'm g\n",
      "Looking for occurrences of idea ...\n",
      "Displaying 4 of 4 matches:\n",
      " . yeah , very good . yeah , i like the idea of make a shape a shape . all right . l\n",
      "ing of making like a courthouse kind of idea and then pulling them around , so havin\n",
      "s . yeah . yeah , sure . so that 's the idea . ideally you hang it on the ceiling , \n",
      "nice . ohh on top is probably is a good idea . you might be able to overlap this cou\n",
      "Looking for occurrences of know ...\n",
      "Displaying 10 of 10 matches:\n",
      " . what are we filming with , because i know my phone does n't have enough storage f\n",
      "like a. ok. just having like . i do n't know , eh ... a couple of these . this diffe\n",
      "se these are pretty sturdy . yeah . you know how to make them . it 's just two paper\n",
      "lity . you make square or like i do n't know how many square . triangles . that 's a\n",
      "ick them wherever is alright . i do n't know . but if you have the sticky bit toward\n",
      "e this ? yeah . or like this . i do n't know how a duck works . maybe we should find\n",
      "thing , all right . yeah . the more you know . this is all detached by the way . oh \n",
      "ere this will just stay ? no . i do n't know . the entire duck is falling apart . i \n",
      "it 's loading how long is it ? i do n't know . it is very quick . it 's actually pre\n",
      " it 's uglier than hopefully , i do n't know . i think some of them are just like le\n",
      "Looking for occurrences of logical ...\n",
      "Displaying 2 of 2 matches:\n",
      "facet . this is the facet ? that seems logical . all right , let 's give it a shot . \n",
      " like this . like… this way seems more logical just take them the other way around . \n",
      "Looking for occurrences of mean ...\n",
      "Displaying 14 of 14 matches:\n",
      "something fun . and we also film it . i mean , we have to make a video recording . o\n",
      "at we 're gon na be in the [ laughs ] i mean , yeah you can . because i have no insp\n",
      "3d or on the wall ? can be combined . i mean , we saw that they don ’ t stick very w\n",
      "we 're just gon na make donald duck . i mean , we also have orange , so . we can do \n",
      " alright . we need to plan this out . i mean , we need a structure on the inside . y\n",
      "ial design engineering , yeah . yes , i mean , ... yeah we can put it on the wall , \n",
      " for an hour of recording ? what do you mean ? are we going to film everything or we\n",
      "everything or we can also just like ? i mean it 's it 's . we can make pictures as w\n",
      "just on the table . oke , so ... do you mean these squares ? yeah , yeah i think so \n",
      "nd then just do it very simply like . i mean this can be a neck if we want to go to \n",
      " globe . yeah , kinda . like a dome . i mean , this is a basis now . like bend it . \n",
      "that ’ s going to be harder , i think i mean , it 's nice if you see . or just . the\n",
      " . we 're going to do this silently . i mean . no conversation . or just very concen\n",
      "as worried we would n't have enough . i mean , we do n't have much yellow left compa\n",
      "Looking for occurrences of plan ...\n",
      "Displaying 3 of 3 matches:\n",
      " we need a shape . alright . we need to plan this out . i mean , we need a structure\n",
      " color in the squares , and then we can plan out where the post-its need to go . ahh\n",
      "ller ? it 's fine . it 's fine . let 's plan out the duck . you can always make it s\n",
      "Looking for occurrences of question ...\n",
      "Displaying 2 of 2 matches:\n",
      "can we use other media , that ’ s the question ? that ’ s the question . ohh . we ca\n",
      " that ’ s the question ? that ’ s the question . ohh . we can also make it like a. v\n",
      "Looking for occurrences of seem ...\n",
      "no matches\n",
      "Looking for occurrences of seems ...\n",
      "Displaying 6 of 6 matches:\n",
      " stop motion video . [ laughter ] so it seems like the post-its find their way onto t\n",
      "an do that from here maybe . yes . this seems like a nice way to like go around to ma\n",
      ". i suppose it does n't stick anymore . seems like a memorable problem that comes bac\n",
      "is the facet . this is the facet ? that seems logical . all right , let 's give it a \n",
      "g against each other . all right . that seems to be all right . we should also attach\n",
      " if we do it like this . like… this way seems more logical just take them the other w\n",
      "Looking for occurrences of solution ...\n",
      "Displaying 3 of 3 matches:\n",
      "s n't stay . i might have a different solution . that might work . let 's see if thi\n",
      "ust left the thing . i found an extra solution . this also works . this is real engi\n",
      "ich way it goes to the camera . final solution .. what needs to happen here ? do we \n",
      "Looking for occurrences of solving ...\n",
      "Displaying 2 of 2 matches:\n",
      "honestly , we 're doing proper problem solving . yeah of course , we ’ re doing prope\n",
      " course , we ’ re doing proper problem solving . we are engineers . all the things i \n",
      "Looking for occurrences of think ...\n",
      "Displaying 25 of 29 matches:\n",
      "one is going to be in the video a lot i think , a duck . [ laughter ] probably . ok. \n",
      " you mean these squares ? yeah , yeah i think so . should make bigger ones , like thi\n",
      "g , but that ’ s going to be harder , i think i mean , it 's nice if you see . or jus\n",
      "? is that in the description ? i do n't think it is ... no , we just need to be like \n",
      "s just two papers and you fold them . i think it 's generally if you have paper , if \n",
      "hanks . this is more difficult than you think . yeah , a good exercise . look at this\n",
      "he body . how high are we gon na go ? i think one more maybe . yeah , i need more pos\n",
      "nda . this sort of something ? yeah . i think . it 's my part , because then you have\n",
      ". all right , let 's give it a shot . i think we need more tape yeah , i can . i can \n",
      " tape . this feels so wasteful . do you think that if we build something like here st\n",
      " but . a duck is , yeah , yeah true . i think it does n't really matter . i think str\n",
      ". i think it does n't really matter . i think structurally this is easier . alright ,\n",
      " this . and then just lay it on top . i think it works ? nice , i have funny hair now\n",
      "do we go , like this ? or like this ? i think if we do it like this . like… this way \n",
      "many post-its do we have left ? cause i think we are going through them quite fast . \n",
      ", this last piece ? the head ? yeah . i think from here just going down . how big are\n",
      "it ? i am not at that stage yet . but i think this is quite nice actually , yeah . ye\n",
      "lier than hopefully , i do n't know . i think some of them are just like letting go a\n",
      "ike letting go after a while . yeah , i think it 's mainly the back that detached at \n",
      "like edit these two together and then i think it 's good . yes , i have . and then re\n",
      " gon na get some help here . ok. no , i think if i touch it and it will fall apart . \n",
      " thinking how i 'm going to do this . i think . i 'm gon na use gravity . i 'm , i 'm\n",
      "nice , well done . nice in one hour . i think we need to leave the room before it fal\n",
      "ompared to with how much we started . i think we have a quarter left . it was a lot o\n",
      "o , it 's half . it 's half past so . i think we did an hour . it does n't ... it was\n",
      "Looking for occurrences of thinking ...\n",
      "Displaying 5 of 5 matches:\n",
      "f storage . yeah , that 's what i was thinking . oh like that . but can you say to a\n",
      "o how do you want to do it 3d . i was thinking of making like a courthouse kind of i\n",
      "gon na be ? it 's kinda small . i was thinking like . something like . something lik\n",
      " s very true . what are these ? i was thinking like the duck . you should have like \n",
      "ecord this . that 's all right . i 'm thinking how i 'm going to do this . i think .\n",
      "Looking for occurrences of thought ...\n",
      "Displaying 2 of 2 matches:\n",
      " some kind of sharp thing some serious thought going into this duck . it 's eh . we '\n",
      " ok , good luck . good luck i have . i thought i was gon na get some help here . ok. \n",
      "Looking for occurrences of understand ...\n",
      "no matches\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "\n",
    "# enter the variable corresponding to the text you plan to examine\n",
    "text_to_examine = transcript_utterances\n",
    "\n",
    "tokens = word_tokenize(text_to_examine.lower())\n",
    "textList = Text(tokens)\n",
    "\n",
    "for term in dictionary_terms_list :\n",
    "    if term in text_to_examine.lower() :\n",
    "        print(\"Looking for occurrences of\", term, \"...\")\n",
    "        textList.concordance(term, width=85, lines=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d0f93-1be6-4297-a273-1d418d7b7d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
