{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc4c443",
   "metadata": {},
   "source": [
    "# Exploring a dictionary-based approach with Empath\n",
    "\n",
    "Empath (see [Fast et al., 2016](https://dl.acm.org/doi/10.1145/2858036.2858535)) is a tool for analysing a given corpus of text to identify the occurrence of certain pre-defined linguistic categories (similar to what is provided by LIWC), but also provides us with a way to create our own linguistic categories based on the behaviour we might want to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f48a0f-1004-4753-bc90-022ae72c6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the below lines if needed.\n",
    "# !conda install empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from empath import Empath\n",
    "from collections import Counter\n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ea799-23e4-47f6-ac66-f7c5037f1ca1",
   "metadata": {},
   "source": [
    "As earlier, we first load the book into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/gutenberg/carroll-alice.txt', 'r', encoding='utf-8-sig') as fo :\n",
    "    book = fo.readlines()\n",
    "\n",
    "# Get rid of lines containing table of contents\n",
    "book=book[23:] \n",
    "\n",
    "# remove all carriage returns within lines.\n",
    "book = [text.replace('\\n', '') for text in book] \n",
    "\n",
    "# remove all empty lines\n",
    "book = [text for text in book if len(text) > 0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fa26c-81c0-458e-888b-0979948decad",
   "metadata": {},
   "source": [
    "## Get the list of categories from Empath (optional)\n",
    "Empath has a set of predefined categories. \n",
    "For this exercise, we will focus on existing categories. \n",
    "We can also create our own category, but let's not worry about it for now.\n",
    "You can uncomment the code below to see a list of all existing categories in Empath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431e2c2-a05a-48cc-aa24-29f4e32cc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see a list of all Empath categories\n",
    "# lexicon.cats.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24a538-5ff0-4f01-82c6-6728b5a833c7",
   "metadata": {},
   "source": [
    "Empath also has a built-in function to analyse a given text against all its categories. Let's use this function. For this, we should treat the entire book as a single 'string' of text, then pass the text to Empath to analyse. \n",
    "The results cover over 195 categories, so we should sort them in descending order, paying attention to the top-scoring categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72376b1-c057-4640-862b-af28f3ef624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_text = ' '.join(book)\n",
    "results = lexicon.analyze(book_text, normalize=True)\n",
    "results_sorted = Counter(results).most_common()\n",
    "print(\"Top five dictionary categories by score:\")\n",
    "results_sorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad240dd-2c34-4a1b-98be-aefb6f3ea8cb",
   "metadata": {},
   "source": [
    "---\n",
    "We can also plot these values for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa8137-4a39-492a-adfd-51699b32b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale=0.9)\n",
    "sns.set_style('ticks')\n",
    "plt.figure(figsize=(4,5))\n",
    "sns.barplot(dict(results_sorted[0:20]), orient='h', color='steelblue')\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f53fb2ce-4675-4ffe-8ccc-b182e2e31edd",
   "metadata": {},
   "source": [
    "## Analysing a piece of text using a particular category in Empath\n",
    "\n",
    "Let's first create a dataframe so we can add any computed metrics alongside each unit of text, like paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7731172-e989-442e-b7f8-fc5d4c4db366",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = pd.DataFrame({'text' : book})\n",
    "print(\"********************************************\")\n",
    "print(\" Loaded\", book_df.shape[0], \"lines of text into dataframe.\")\n",
    "print(\"********************************************\")\n",
    "book_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70f05c",
   "metadata": {},
   "source": [
    "We can create a function for this approach so that we can pass this function to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7725ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_category(text, category_name, normalize=True):\n",
    "    score = lexicon.analyze(text, categories=[category_name], normalize=normalize)\n",
    "    return score[category_name]\n",
    "\n",
    "category = 'shape_and_size'\n",
    "book_df[category] = book_df.apply(\n",
    "                        lambda x: calc_category(x['text'], category,\n",
    "                                                normalize=False),\n",
    "                        axis=1)\n",
    "book_df.sample(5)                                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec4f7f-e173-40ec-9463-14ab8fc30d51",
   "metadata": {},
   "source": [
    "---\n",
    "Recall the use of `lambda` from the previous notebook. \n",
    "\n",
    "In the above code, we use it pass the function we created (`calc_category`) to a built-in function within pandas which allows us to apply an operation to an entire column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9851b13-233f-49dd-9d2f-c9b0d61b178d",
   "metadata": {},
   "source": [
    "---\n",
    "We can now examine how our category score changes over the length of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43eb12-9772-4b07-a9fe-95d7f6cf4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f780825-c241-42d3-b384-d4abfd50c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3),dpi=600)\n",
    "g = sns.lineplot(data = book_df, y=category, x=book_df.index,\n",
    "                 color='steelblue', lw=0.5)\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e598c5d-9d5c-4a03-988c-5a774d0c797a",
   "metadata": {},
   "source": [
    "We can then choose a particular range of line numbers and examine the text closely against the category scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7aa1b-ab26-456d-a198-ce33fcd4f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,6))\n",
    "# sns.set_context('notebook', font_scale=0.7)\n",
    "g = sns.barplot(data = book_df[675:700], x=category, y='text',\n",
    "                color='steelblue')\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf30c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,6))\n",
    "category_text_df = book_df[book_df[category] > 0]\n",
    "g = sns.barplot(data = category_text_df[0:25], x=category, y='text',\n",
    "                color='steelblue')\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f91427-ec83-4b13-a432-b8c0a50b9a1a",
   "metadata": {},
   "source": [
    "## A similar approach for sentiment analysis\n",
    "We can either add more dictionary categories, or use a different metric.\n",
    "Let's try sentiment analysis, for which we will use [VADER](https://github.com/cjhutto/vaderSentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a79f3-ea2c-49cf-a02f-6ce4ead681fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line if you don't have VADER installed.\n",
    "# !conda install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e20f56-5880-4fe3-98f9-0c1832914be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text) :\n",
    "    vs = analyzer.polarity_scores(text)['compound']\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a4929-3183-45be-bf05-7a40721e45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['sentiment'] = book_df['text'].apply(sentiment)\n",
    "book_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df47d14-6f97-4d5e-9f76-409490181a7d",
   "metadata": {},
   "source": [
    "As in the earlier case, we can visualize the scores, this time using different colours for positive and negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84079be-ef92-4e05-9b5d-a81f710d2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,6))\n",
    "sns.barplot(data=book_df[-30:], x='sentiment', y='text',hue='sentiment',\n",
    "            palette=sns.color_palette(\"vlag_r\", as_cmap=True), legend=None)\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee544c-ddd3-4d84-92eb-97d803f9df63",
   "metadata": {},
   "source": [
    "Do you observe anything interesting in how the sentiment changes over parts of your story?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036d3f8-8cc6-4437-b6aa-4221f7d91989",
   "metadata": {},
   "source": [
    "## Studying correlations\n",
    "Do you notice any correlations between your chosen LIWC/Empath measure and sentiment? \n",
    "You can use a 2D histogram to plot them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebff5f8-0991-4afa-b9a2-0b102fd37453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "g = sns.histplot(data=book_df, x=category, y=\"sentiment\")\n",
    "sns.despine(right=True, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4e388-e133-4a23-9e0b-b2007ba454a0",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "What kind of hunch do you have about the tone, style, or themes of your favourite book? How will you verify it?\n",
    "\n",
    "Can you use this approach to compare tones and styles across different books? How will you try it out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53d231-be95-46c0-96d6-d4e05c4baa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
